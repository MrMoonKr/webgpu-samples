(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[342],{5671:function(e,n,t){"use strict";t.d(n,{T:function(){return f}});var r=t(5893),a=t(9008),i=t.n(a),o=t(1163),s=t(7294),u=t(9147),c=t.n(u);let l="undefined"!=typeof GPUDevice&&t(6257).setShaderRegisteredCallback;t(7319);let d=e=>{let n=(0,s.useRef)(null),a=(0,s.useMemo)(()=>e.sources.map(e=>{let{name:n,contents:a,editable:i}=e;return{name:n,...function(e,n){let a;let i=null,o=[];{i=document.createElement("div");let s=t(4631);(a=s(i,{lineNumbers:!0,lineWrapping:!0,theme:"monokai",readOnly:!n})).updatedSource=function(e){o.forEach(n=>n(e))}}return{updateCallbacks:o,Container:function(t){return(0,r.jsxs)("div",{...t,children:[n?(0,r.jsx)("button",{className:c().updateSourceBtn,onClick(){a.updatedSource(a.getValue())},children:"Update"}):null,(0,r.jsx)("div",{ref(n){i&&n&&(n.appendChild(i),a.setOption("value",e))}})]})}}}(a,i)}}),e.sources),u=(0,s.useRef)(null),d=(0,s.useMemo)(()=>{if(e.gui){let n=t(4376);return new n.GUI({autoPlace:!1})}},[]),f=(0,o.useRouter)(),p=f.asPath.match(/#([a-zA-Z0-9\.\/]+)/),[m,h]=(0,s.useState)(null),[g,x]=(0,s.useState)(null);return(0,s.useEffect)(()=>{p?x(p[1]):x(a[0].name),d&&u.current&&u.current.appendChild(d.domElement);let t={active:!0},r=()=>{t.active=!1};try{let i=n.current,o=e.init({canvas:i,pageState:t,gui:d});o instanceof Promise&&o.catch(e=>{console.error(e),h(e)})}catch(s){console.error(s),h(s)}return r},[]),(0,s.useEffect)(()=>{l&&l((n,t)=>{let r=e.sources.findIndex(e=>{let{contents:t}=e;return t==n});a[r].updateCallbacks.push(t)})},[a]),(0,r.jsxs)("main",{children:[(0,r.jsxs)(i(),{children:[(0,r.jsx)("style",{dangerouslySetInnerHTML:{__html:"\n            .CodeMirror {\n              height: auto !important;\n              margin: 1em 0;\n            }\n\n            .CodeMirror-scroll {\n              height: auto !important;\n              overflow: visible !important;\n            }\n          "}}),(0,r.jsx)("title",{children:"".concat(e.name," - WebGPU Samples")}),(0,r.jsx)("meta",{name:"description",content:e.description})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("h1",{children:e.name}),(0,r.jsx)("a",{target:"_blank",rel:"noreferrer",href:"https://github.com/austinEng/webgpu-samples/tree/main/".concat(e.filename),children:"See it on Github!"}),(0,r.jsx)("p",{children:e.description}),m?(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("p",{children:"Is WebGPU Enabled?"}),(0,r.jsx)("p",{children:"".concat(m)})]}):null]}),(0,r.jsxs)("div",{className:c().canvasContainer,children:[(0,r.jsx)("div",{style:{position:"absolute",right:10},ref:u}),(0,r.jsx)("canvas",{ref:n,width:600,height:600})]}),(0,r.jsxs)("div",{children:[(0,r.jsx)("nav",{className:c().sourceFileNav,children:(0,r.jsx)("ul",{children:a.map((e,n)=>(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"#".concat(e.name),"data-active":g==e.name,onClick(){x(e.name)},children:e.name})},n))})}),a.map((e,n)=>(0,r.jsx)(e.Container,{className:c().sourceFileContainer,"data-active":g==e.name},n))]})]})},f=e=>(0,r.jsx)(d,{...e})},3057:function(e,n,t){"use strict";t.d(n,{W:function(){return o}});var r=t(6906),a=t(7160);let i={xy:[0,1],xz:[0,2],yz:[1,2]},o={positions:r.m,triangles:r.g,normals:[],uvs:[]};o.normals=function(e,n){let t=e.map(()=>[0,0,0]);return n.forEach(n=>{let[r,i,o]=n,s=e[r],u=e[i],c=e[o],l=a.$X(a.Ue(),u,s),d=a.$X(a.Ue(),c,s);a.Fv(l,l),a.Fv(d,d);let f=a.kC(a.Ue(),l,d);a.IH(t[r],t[r],f),a.IH(t[i],t[i],f),a.IH(t[o],t[o],f)}),t.forEach(e=>{a.Fv(e,e)}),t}(o.positions,o.triangles),o.uvs=function(e){let n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:"xy",t=i[n],r=e.map(()=>[0,0]),a=[1/0,1/0],o=[-1/0,-1/0];return e.forEach((e,n)=>{r[n][0]=e[t[0]],r[n][1]=e[t[1]],a[0]=Math.min(e[t[0]],a[0]),a[1]=Math.min(e[t[1]],a[1]),o[0]=Math.max(e[t[0]],o[0]),o[1]=Math.max(e[t[1]],o[1])}),r.forEach(e=>{e[0]=(e[0]-a[0])/(o[0]-a[0]),e[1]=(e[1]-a[1])/(o[1]-a[1])}),r}(o.positions,"xy"),o.triangles.push([o.positions.length,o.positions.length+2,o.positions.length+1],[o.positions.length,o.positions.length+1,o.positions.length+3]),o.positions.push([-100,20,-100],[100,20,100],[-100,20,100],[100,20,-100]),o.normals.push([0,1,0],[0,1,0],[0,1,0],[0,1,0]),o.uvs.push([0,0],[1,1],[0,1],[1,0])},2342:function(e,n,t){"use strict";t.r(n),t.d(n,{default:function(){return p}});var r=t(7160),a=t(5975),i=t(5671),o=t(3057),s="struct Scene {\n  lightViewProjMatrix: mat4x4<f32>,\n  cameraViewProjMatrix: mat4x4<f32>,\n  lightPos: vec3f,\n}\n\nstruct Model {\n  modelMatrix: mat4x4<f32>,\n}\n\n@group(0) @binding(0) var<uniform> scene : Scene;\n@group(1) @binding(0) var<uniform> model : Model;\n\n@vertex\nfn main(\n  @location(0) position: vec3f\n) -> @builtin(position) vec4f {\n  return scene.lightViewProjMatrix * model.modelMatrix * vec4(position, 1);\n}\n",u="struct Scene {\n  lightViewProjMatrix: mat4x4<f32>,\n  cameraViewProjMatrix: mat4x4<f32>,\n  lightPos: vec3f,\n}\n\nstruct Model {\n  modelMatrix: mat4x4<f32>,\n}\n\n@group(0) @binding(0) var<uniform> scene : Scene;\n@group(1) @binding(0) var<uniform> model : Model;\n\nstruct VertexOutput {\n  @location(0) shadowPos: vec3f,\n  @location(1) fragPos: vec3f,\n  @location(2) fragNorm: vec3f,\n\n  @builtin(position) Position: vec4f,\n}\n\n@vertex\nfn main(\n  @location(0) position: vec3f,\n  @location(1) normal: vec3f\n) -> VertexOutput {\n  var output : VertexOutput;\n\n  // XY is in (-1, 1) space, Z is in (0, 1) space\n  let posFromLight = scene.lightViewProjMatrix * model.modelMatrix * vec4(position, 1);\n\n  // Convert XY to (0, 1)\n  // Y is flipped because texture coords are Y-down.\n  output.shadowPos = vec3(\n    posFromLight.xy * vec2(0.5, -0.5) + vec2(0.5),\n    posFromLight.z\n  );\n\n  output.Position = scene.cameraViewProjMatrix * model.modelMatrix * vec4(position, 1);\n  output.fragPos = output.Position.xyz;\n  output.fragNorm = normal;\n  return output;\n}\n",c="// TODO: Use pipeline constants\nconst shadowDepthTextureSize = 1024;\n\nstruct Scene {\n  lightViewProjMatrix : mat4x4<f32>,\n  cameraViewProjMatrix : mat4x4<f32>,\n  lightPos : vec3f,\n}\n\n@group(0) @binding(0) var<uniform> scene : Scene;\n@group(0) @binding(1) var shadowMap: texture_depth_2d;\n@group(0) @binding(2) var shadowSampler: sampler_comparison;\n\nstruct FragmentInput {\n  @location(0) shadowPos : vec3f,\n  @location(1) fragPos : vec3f,\n  @location(2) fragNorm : vec3f,\n}\n\nconst albedo = vec3(0.9);\nconst ambientFactor = 0.2;\n\n@fragment\nfn main(input : FragmentInput) -> @location(0) vec4f {\n  // Percentage-closer filtering. Sample texels in the region\n  // to smooth the result.\n  var visibility = 0f;\n  let oneOverShadowDepthTextureSize = 1.0 / shadowDepthTextureSize;\n  for (var y = -1; y <= 1; y++) {\n    for (var x = -1; x <= 1; x++) {\n      let offset = vec2f(vec2(x, y)) * oneOverShadowDepthTextureSize;\n\n      visibility += textureSampleCompare(\n        shadowMap, shadowSampler,\n        input.shadowPos.xy + offset, input.shadowPos.z - 0.007\n      );\n    }\n  }\n  visibility /= 9;\n\n  let lambertFactor = max(dot(normalize(scene.lightPos - input.fragPos), input.fragNorm), 0);\n  let lightingFactor = min(ambientFactor + visibility * lambertFactor, 1);\n\n  return vec4(lightingFactor * albedo, 1);\n}\n",l="src/sample/shadowMapping/main.ts";let d=async e=>{let{canvas:n,pageState:t}=e,i=await navigator.gpu.requestAdapter(),l=await i.requestDevice();if(!t.active)return;let d=n.getContext("webgpu"),f=window.devicePixelRatio||1,p=[n.clientWidth*f,n.clientHeight*f],m=p[0]/p[1],h=navigator.gpu.getPreferredCanvasFormat();d.configure({device:l,size:p,format:h,alphaMode:"opaque"});let g=l.createBuffer({size:6*o.W.positions.length*Float32Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.VERTEX,mappedAtCreation:!0});{let x=new Float32Array(g.getMappedRange());for(let v=0;v<o.W.positions.length;++v)x.set(o.W.positions[v],6*v),x.set(o.W.normals[v],6*v+3);g.unmap()}let P=3*o.W.triangles.length,w=l.createBuffer({size:P*Uint16Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.INDEX,mappedAtCreation:!0});{let b=new Uint16Array(w.getMappedRange());for(let S=0;S<o.W.triangles.length;++S)b.set(o.W.triangles[S],3*S);w.unmap()}let y=l.createTexture({size:[1024,1024,1],usage:GPUTextureUsage.RENDER_ATTACHMENT|GPUTextureUsage.TEXTURE_BINDING,format:"depth32float"}),M=y.createView(),B=[{arrayStride:6*Float32Array.BYTES_PER_ELEMENT,attributes:[{shaderLocation:0,offset:0,format:"float32x3"},{shaderLocation:1,offset:3*Float32Array.BYTES_PER_ELEMENT,format:"float32x3"}]}],E={topology:"triangle-list",cullMode:"back"},G=l.createBindGroupLayout({entries:[{binding:0,visibility:GPUShaderStage.VERTEX,buffer:{type:"uniform"}}]}),U=l.createRenderPipeline({layout:l.createPipelineLayout({bindGroupLayouts:[G,G]}),vertex:{module:l.createShaderModule({code:s}),entryPoint:"main",buffers:B},depthStencil:{depthWriteEnabled:!0,depthCompare:"less",format:"depth32float"},primitive:E}),T=l.createBindGroupLayout({entries:[{binding:0,visibility:GPUShaderStage.VERTEX|GPUShaderStage.FRAGMENT,buffer:{type:"uniform"}},{binding:1,visibility:GPUShaderStage.VERTEX|GPUShaderStage.FRAGMENT,texture:{sampleType:"depth"}},{binding:2,visibility:GPUShaderStage.VERTEX|GPUShaderStage.FRAGMENT,sampler:{type:"comparison"}}]}),R=l.createRenderPipeline({layout:l.createPipelineLayout({bindGroupLayouts:[T,G]}),vertex:{module:l.createShaderModule({code:u}),entryPoint:"main",buffers:B},fragment:{module:l.createShaderModule({code:c}),entryPoint:"main",targets:[{format:h}]},depthStencil:{depthWriteEnabled:!0,depthCompare:"less",format:"depth24plus-stencil8"},primitive:E}),V=l.createTexture({size:p,format:"depth24plus-stencil8",usage:GPUTextureUsage.RENDER_ATTACHMENT}),L={colorAttachments:[{view:void 0,clearValue:{r:.5,g:.5,b:.5,a:1},loadOp:"clear",storeOp:"store"}],depthStencilAttachment:{view:V.createView(),depthClearValue:1,depthLoadOp:"clear",depthStoreOp:"store",stencilClearValue:0,stencilLoadOp:"clear",stencilStoreOp:"store"}},C=l.createBuffer({size:64,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),F=l.createBuffer({size:140,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),_=l.createBindGroup({layout:G,entries:[{binding:0,resource:{buffer:F}}]}),j=l.createBindGroup({layout:T,entries:[{binding:0,resource:{buffer:F}},{binding:1,resource:M},{binding:2,resource:l.createSampler({compare:"less"})}]}),A=l.createBindGroup({layout:G,entries:[{binding:0,resource:{buffer:C}}]}),D=r.al(0,50,-100),N=r.al(0,1,0),O=r.al(0,0,0),z=a.Ue();a.G3(z,2*Math.PI/5,m,1,2e3);let I=a.Ue();a.zB(I,D,O,N);let W=r.al(50,100,-100),q=a.Ue();a.zB(q,W,O,N);let X=a.Ue();a.M5(X,-80,80,-80,80,-200,300);let k=a.Ue();a.Jp(k,X,q);let Y=a.Ue();a.Jp(Y,z,I);let H=a.Ue();a.Iu(H,H,r.al(0,-5,0)),a.Iu(H,H,r.al(0,-40,0)),l.queue.writeBuffer(F,0,k.buffer,k.byteOffset,k.byteLength),l.queue.writeBuffer(F,64,Y.buffer,Y.byteOffset,Y.byteLength),l.queue.writeBuffer(F,128,W.buffer,W.byteOffset,W.byteLength),l.queue.writeBuffer(C,0,H.buffer,H.byteOffset,H.byteLength);let J={colorAttachments:[],depthStencilAttachment:{view:M,depthClearValue:1,depthLoadOp:"clear",depthStoreOp:"store"}};requestAnimationFrame(function e(){if(!t.active)return;let n=function(){let e=r.al(0,50,-100),n=Math.PI*(Date.now()/2e3);r.uD(e,e,O,n);let t=a.Ue();return a.zB(t,e,O,N),a.Jp(Y,z,t),Y}();l.queue.writeBuffer(F,64,n.buffer,n.byteOffset,n.byteLength),L.colorAttachments[0].view=d.getCurrentTexture().createView();let i=l.createCommandEncoder();{let o=i.beginRenderPass(J);o.setPipeline(U),o.setBindGroup(0,_),o.setBindGroup(1,A),o.setVertexBuffer(0,g),o.setIndexBuffer(w,"uint16"),o.drawIndexed(P),o.end()}{let s=i.beginRenderPass(L);s.setPipeline(R),s.setBindGroup(0,j),s.setBindGroup(1,A),s.setVertexBuffer(0,g),s.setIndexBuffer(w,"uint16"),s.drawIndexed(P),s.end()}l.queue.submit([i.finish()]),requestAnimationFrame(e)})},f=()=>(0,i.T)({name:"Shadow Mapping",description:"This example shows how to sample from a depth texture to render shadows.",init:d,sources:[{name:l.substring(25),contents:"import { mat4, vec3 } from 'gl-matrix';\nimport { makeSample, SampleInit } from '../../components/SampleLayout';\n\nimport { mesh } from '../../meshes/stanfordDragon';\n\nimport vertexShadowWGSL from './vertexShadow.wgsl';\nimport vertexWGSL from './vertex.wgsl';\nimport fragmentWGSL from './fragment.wgsl';\n\nconst shadowDepthTextureSize = 1024;\n\nconst init: SampleInit = async ({ canvas, pageState }) => {\n  const adapter = await navigator.gpu.requestAdapter();\n  const device = await adapter.requestDevice();\n\n  if (!pageState.active) return;\n\n  const context = canvas.getContext('webgpu') as GPUCanvasContext;\n\n  const devicePixelRatio = window.devicePixelRatio || 1;\n  const presentationSize = [\n    canvas.clientWidth * devicePixelRatio,\n    canvas.clientHeight * devicePixelRatio,\n  ];\n  const aspect = presentationSize[0] / presentationSize[1];\n  const presentationFormat = navigator.gpu.getPreferredCanvasFormat();\n  context.configure({\n    device,\n    size: presentationSize,\n    format: presentationFormat,\n    alphaMode: 'opaque',\n  });\n\n  // Create the model vertex buffer.\n  const vertexBuffer = device.createBuffer({\n    size: mesh.positions.length * 3 * 2 * Float32Array.BYTES_PER_ELEMENT,\n    usage: GPUBufferUsage.VERTEX,\n    mappedAtCreation: true,\n  });\n  {\n    const mapping = new Float32Array(vertexBuffer.getMappedRange());\n    for (let i = 0; i < mesh.positions.length; ++i) {\n      mapping.set(mesh.positions[i], 6 * i);\n      mapping.set(mesh.normals[i], 6 * i + 3);\n    }\n    vertexBuffer.unmap();\n  }\n\n  // Create the model index buffer.\n  const indexCount = mesh.triangles.length * 3;\n  const indexBuffer = device.createBuffer({\n    size: indexCount * Uint16Array.BYTES_PER_ELEMENT,\n    usage: GPUBufferUsage.INDEX,\n    mappedAtCreation: true,\n  });\n  {\n    const mapping = new Uint16Array(indexBuffer.getMappedRange());\n    for (let i = 0; i < mesh.triangles.length; ++i) {\n      mapping.set(mesh.triangles[i], 3 * i);\n    }\n    indexBuffer.unmap();\n  }\n\n  // Create the depth texture for rendering/sampling the shadow map.\n  const shadowDepthTexture = device.createTexture({\n    size: [shadowDepthTextureSize, shadowDepthTextureSize, 1],\n    usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.TEXTURE_BINDING,\n    format: 'depth32float',\n  });\n  const shadowDepthTextureView = shadowDepthTexture.createView();\n\n  // Create some common descriptors used for both the shadow pipeline\n  // and the color rendering pipeline.\n  const vertexBuffers: Iterable<GPUVertexBufferLayout> = [\n    {\n      arrayStride: Float32Array.BYTES_PER_ELEMENT * 6,\n      attributes: [\n        {\n          // position\n          shaderLocation: 0,\n          offset: 0,\n          format: 'float32x3',\n        },\n        {\n          // normal\n          shaderLocation: 1,\n          offset: Float32Array.BYTES_PER_ELEMENT * 3,\n          format: 'float32x3',\n        },\n      ],\n    },\n  ];\n\n  const primitive: GPUPrimitiveState = {\n    topology: 'triangle-list',\n    cullMode: 'back',\n  };\n\n  const uniformBufferBindGroupLayout = device.createBindGroupLayout({\n    entries: [\n      {\n        binding: 0,\n        visibility: GPUShaderStage.VERTEX,\n        buffer: {\n          type: 'uniform',\n        },\n      },\n    ],\n  });\n\n  const shadowPipeline = device.createRenderPipeline({\n    layout: device.createPipelineLayout({\n      bindGroupLayouts: [\n        uniformBufferBindGroupLayout,\n        uniformBufferBindGroupLayout,\n      ],\n    }),\n    vertex: {\n      module: device.createShaderModule({\n        code: vertexShadowWGSL,\n      }),\n      entryPoint: 'main',\n      buffers: vertexBuffers,\n    },\n    depthStencil: {\n      depthWriteEnabled: true,\n      depthCompare: 'less',\n      format: 'depth32float',\n    },\n    primitive,\n  });\n\n  // Create a bind group layout which holds the scene uniforms and\n  // the texture+sampler for depth. We create it manually because the WebPU\n  // implementation doesn't infer this from the shader (yet).\n  const bglForRender = device.createBindGroupLayout({\n    entries: [\n      {\n        binding: 0,\n        visibility: GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT,\n        buffer: {\n          type: 'uniform',\n        },\n      },\n      {\n        binding: 1,\n        visibility: GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT,\n        texture: {\n          sampleType: 'depth',\n        },\n      },\n      {\n        binding: 2,\n        visibility: GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT,\n        sampler: {\n          type: 'comparison',\n        },\n      },\n    ],\n  });\n\n  const pipeline = device.createRenderPipeline({\n    layout: device.createPipelineLayout({\n      bindGroupLayouts: [bglForRender, uniformBufferBindGroupLayout],\n    }),\n    vertex: {\n      module: device.createShaderModule({\n        code: vertexWGSL,\n      }),\n      entryPoint: 'main',\n      buffers: vertexBuffers,\n    },\n    fragment: {\n      module: device.createShaderModule({\n        code: fragmentWGSL,\n      }),\n      entryPoint: 'main',\n      targets: [\n        {\n          format: presentationFormat,\n        },\n      ],\n    },\n    depthStencil: {\n      depthWriteEnabled: true,\n      depthCompare: 'less',\n      format: 'depth24plus-stencil8',\n    },\n    primitive,\n  });\n\n  const depthTexture = device.createTexture({\n    size: presentationSize,\n    format: 'depth24plus-stencil8',\n    usage: GPUTextureUsage.RENDER_ATTACHMENT,\n  });\n\n  const renderPassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [\n      {\n        // view is acquired and set in render loop.\n        view: undefined,\n\n        clearValue: { r: 0.5, g: 0.5, b: 0.5, a: 1.0 },\n        loadOp: 'clear',\n        storeOp: 'store',\n      },\n    ],\n    depthStencilAttachment: {\n      view: depthTexture.createView(),\n\n      depthClearValue: 1.0,\n      depthLoadOp: 'clear',\n      depthStoreOp: 'store',\n      stencilClearValue: 0,\n      stencilLoadOp: 'clear',\n      stencilStoreOp: 'store',\n    },\n  };\n\n  const modelUniformBuffer = device.createBuffer({\n    size: 4 * 16, // 4x4 matrix\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n\n  const sceneUniformBuffer = device.createBuffer({\n    // Two 4x4 viewProj matrices,\n    // one for the camera and one for the light.\n    // Then a vec3 for the light position.\n    size: 2 * 4 * 16 + 3 * 4,\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n\n  const sceneBindGroupForShadow = device.createBindGroup({\n    layout: uniformBufferBindGroupLayout,\n    entries: [\n      {\n        binding: 0,\n        resource: {\n          buffer: sceneUniformBuffer,\n        },\n      },\n    ],\n  });\n\n  const sceneBindGroupForRender = device.createBindGroup({\n    layout: bglForRender,\n    entries: [\n      {\n        binding: 0,\n        resource: {\n          buffer: sceneUniformBuffer,\n        },\n      },\n      {\n        binding: 1,\n        resource: shadowDepthTextureView,\n      },\n      {\n        binding: 2,\n        resource: device.createSampler({\n          compare: 'less',\n        }),\n      },\n    ],\n  });\n\n  const modelBindGroup = device.createBindGroup({\n    layout: uniformBufferBindGroupLayout,\n    entries: [\n      {\n        binding: 0,\n        resource: {\n          buffer: modelUniformBuffer,\n        },\n      },\n    ],\n  });\n\n  const eyePosition = vec3.fromValues(0, 50, -100);\n  const upVector = vec3.fromValues(0, 1, 0);\n  const origin = vec3.fromValues(0, 0, 0);\n\n  const projectionMatrix = mat4.create();\n  mat4.perspective(projectionMatrix, (2 * Math.PI) / 5, aspect, 1, 2000.0);\n\n  const viewMatrix = mat4.create();\n  mat4.lookAt(viewMatrix, eyePosition, origin, upVector);\n\n  const lightPosition = vec3.fromValues(50, 100, -100);\n  const lightViewMatrix = mat4.create();\n  mat4.lookAt(lightViewMatrix, lightPosition, origin, upVector);\n\n  const lightProjectionMatrix = mat4.create();\n  {\n    const left = -80;\n    const right = 80;\n    const bottom = -80;\n    const top = 80;\n    const near = -200;\n    const far = 300;\n    mat4.ortho(lightProjectionMatrix, left, right, bottom, top, near, far);\n  }\n\n  const lightViewProjMatrix = mat4.create();\n  mat4.multiply(lightViewProjMatrix, lightProjectionMatrix, lightViewMatrix);\n\n  const viewProjMatrix = mat4.create();\n  mat4.multiply(viewProjMatrix, projectionMatrix, viewMatrix);\n\n  // Move the model so it's centered.\n  const modelMatrix = mat4.create();\n  mat4.translate(modelMatrix, modelMatrix, vec3.fromValues(0, -5, 0));\n  mat4.translate(modelMatrix, modelMatrix, vec3.fromValues(0, -40, 0));\n\n  // The camera/light aren't moving, so write them into buffers now.\n  {\n    const lightMatrixData = lightViewProjMatrix as Float32Array;\n    device.queue.writeBuffer(\n      sceneUniformBuffer,\n      0,\n      lightMatrixData.buffer,\n      lightMatrixData.byteOffset,\n      lightMatrixData.byteLength\n    );\n\n    const cameraMatrixData = viewProjMatrix as Float32Array;\n    device.queue.writeBuffer(\n      sceneUniformBuffer,\n      64,\n      cameraMatrixData.buffer,\n      cameraMatrixData.byteOffset,\n      cameraMatrixData.byteLength\n    );\n\n    const lightData = lightPosition as Float32Array;\n    device.queue.writeBuffer(\n      sceneUniformBuffer,\n      128,\n      lightData.buffer,\n      lightData.byteOffset,\n      lightData.byteLength\n    );\n\n    const modelData = modelMatrix as Float32Array;\n    device.queue.writeBuffer(\n      modelUniformBuffer,\n      0,\n      modelData.buffer,\n      modelData.byteOffset,\n      modelData.byteLength\n    );\n  }\n\n  // Rotates the camera around the origin based on time.\n  function getCameraViewProjMatrix() {\n    const eyePosition = vec3.fromValues(0, 50, -100);\n\n    const rad = Math.PI * (Date.now() / 2000);\n    vec3.rotateY(eyePosition, eyePosition, origin, rad);\n\n    const viewMatrix = mat4.create();\n    mat4.lookAt(viewMatrix, eyePosition, origin, upVector);\n\n    mat4.multiply(viewProjMatrix, projectionMatrix, viewMatrix);\n    return viewProjMatrix as Float32Array;\n  }\n\n  const shadowPassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [],\n    depthStencilAttachment: {\n      view: shadowDepthTextureView,\n      depthClearValue: 1.0,\n      depthLoadOp: 'clear',\n      depthStoreOp: 'store',\n    },\n  };\n\n  function frame() {\n    // Sample is no longer the active page.\n    if (!pageState.active) return;\n\n    const cameraViewProj = getCameraViewProjMatrix();\n    device.queue.writeBuffer(\n      sceneUniformBuffer,\n      64,\n      cameraViewProj.buffer,\n      cameraViewProj.byteOffset,\n      cameraViewProj.byteLength\n    );\n\n    renderPassDescriptor.colorAttachments[0].view = context\n      .getCurrentTexture()\n      .createView();\n\n    const commandEncoder = device.createCommandEncoder();\n    {\n      const shadowPass = commandEncoder.beginRenderPass(shadowPassDescriptor);\n      shadowPass.setPipeline(shadowPipeline);\n      shadowPass.setBindGroup(0, sceneBindGroupForShadow);\n      shadowPass.setBindGroup(1, modelBindGroup);\n      shadowPass.setVertexBuffer(0, vertexBuffer);\n      shadowPass.setIndexBuffer(indexBuffer, 'uint16');\n      shadowPass.drawIndexed(indexCount);\n\n      shadowPass.end();\n    }\n    {\n      const renderPass = commandEncoder.beginRenderPass(renderPassDescriptor);\n      renderPass.setPipeline(pipeline);\n      renderPass.setBindGroup(0, sceneBindGroupForRender);\n      renderPass.setBindGroup(1, modelBindGroup);\n      renderPass.setVertexBuffer(0, vertexBuffer);\n      renderPass.setIndexBuffer(indexBuffer, 'uint16');\n      renderPass.drawIndexed(indexCount);\n\n      renderPass.end();\n    }\n    device.queue.submit([commandEncoder.finish()]);\n    requestAnimationFrame(frame);\n  }\n  requestAnimationFrame(frame);\n};\n\nconst ShadowMapping: () => JSX.Element = () =>\n  makeSample({\n    name: 'Shadow Mapping',\n    description:\n      'This example shows how to sample from a depth texture to render shadows.',\n    init,\n    sources: [\n      {\n        name: __filename.substring(__dirname.length + 1),\n        contents: __SOURCE__,\n      },\n      {\n        name: './vertexShadow.wgsl',\n        contents: vertexShadowWGSL,\n        editable: true,\n      },\n      {\n        name: './vertex.wgsl',\n        contents: vertexWGSL,\n        editable: true,\n      },\n      {\n        name: './fragment.wgsl',\n        contents: fragmentWGSL,\n        editable: true,\n      },\n    ],\n    filename: __filename,\n  });\n\nexport default ShadowMapping;\n"},{name:"./vertexShadow.wgsl",contents:s,editable:!0},{name:"./vertex.wgsl",contents:u,editable:!0},{name:"./fragment.wgsl",contents:c,editable:!0}],filename:l});var p=f},9147:function(e){e.exports={canvasContainer:"SampleLayout_canvasContainer__zRR_l",sourceFileNav:"SampleLayout_sourceFileNav__ml48P",sourceFileContainer:"SampleLayout_sourceFileContainer__3s84x",updateSourceBtn:"SampleLayout_updateSourceBtn__L2sFc"}}}]);